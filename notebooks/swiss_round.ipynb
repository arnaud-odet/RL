{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rl_lib.swiss_round.environment import SwissRoundEnv\n",
    "from rl_lib.swiss_round.agent import DQNAgent\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_teams = 18\n",
    "n_rounds = 6\n",
    "team_strengths = [1 * 0.5 ** i for i in range(n_teams)]\n",
    "threshold_ranks = [4,12]\n",
    "bonus_points = [20,20]\n",
    "#agent_id = threshold_ranks[-1] #Agent_id just below last threshold\n",
    "agent_id=0\n",
    "\n",
    "env = SwissRoundEnv(\n",
    "    n_teams=n_teams,\n",
    "    n_rounds=n_rounds,\n",
    "    team_strengths=team_strengths,\n",
    "    threshold_ranks=threshold_ranks,\n",
    "    bonus_points=bonus_points,\n",
    "    agent_id=agent_id,\n",
    "    max_draw_probability=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating tournaments: 100%|██████████| 2000/2000 [00:07<00:00, 253.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 19 simulations failed out of 2000 (0.9%)\n",
      "Baseline WinAll average reward = 44.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Team           0.000000\n",
       "Strength       1.000000\n",
       "Avg_Points    12.201918\n",
       "Avg_Rank       4.353357\n",
       "Top-4 %        0.656739\n",
       "Top-12 %       0.931853\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_wa = env.simulate_n_tournaments(2000,\n",
    "                                           n_cores = 24, \n",
    "                                           policy = 'win_all',\n",
    "                                           display_results=False)\n",
    "baseline_reward_wa = simulation_wa.loc[agent_id,'Avg_Points'] + sum([b * simulation_wa.loc[agent_id,f\"Top-{t} %\"] for b,t in zip(\n",
    "    bonus_points, threshold_ranks\n",
    ")])\n",
    "print(f\"Baseline WinAll average reward = {baseline_reward_wa:.1f}\")\n",
    "simulation_wa.loc[agent_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating tournaments: 100%|██████████| 2000/2000 [00:08<00:00, 229.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 12 simulations failed out of 2000 (0.6%)\n",
      "Baseline LoseFirst average reward = 35.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Team           0.000000\n",
       "Strength       1.000000\n",
       "Avg_Points    10.242455\n",
       "Avg_Rank       6.764085\n",
       "Top-4 %        0.416499\n",
       "Top-12 %       0.844567\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_lf = env.simulate_n_tournaments(2000,n_cores = 24, policy = 'lose_first',display_results=False)\n",
    "baseline_reward_lf = simulation_lf.loc[agent_id,'Avg_Points'] + sum([b * simulation_lf.loc[agent_id,f\"Top-{t} %\"] for b,t in zip(\n",
    "    bonus_points, threshold_ranks\n",
    ")])\n",
    "print(f\"Baseline LoseFirst average reward = {baseline_reward_lf:.1f}\")\n",
    "simulation_lf.loc[agent_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselines average reward : WinAll = 44.0, LoseFirst = 35.5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baselines average reward : WinAll = {baseline_reward_wa:.1f}, LoseFirst = {baseline_reward_lf:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/4000 | Avg Reward: 12.11 | Avg nb gambits played 4.18 | Epsilon: 0.995 | Failed episodes: 0\n",
      "Episode 200/4000 | Avg Reward: 11.85 | Avg nb gambits played 4.07 | Epsilon: 0.989 | Failed episodes: 0\n",
      "Episode 300/4000 | Avg Reward: 10.69 | Avg nb gambits played 4.08 | Epsilon: 0.983 | Failed episodes: 0\n",
      "Episode 400/4000 | Avg Reward: 14.12 | Avg nb gambits played 3.89 | Epsilon: 0.977 | Failed episodes: 0\n",
      "Episode 500/4000 | Avg Reward: 13.96 | Avg nb gambits played 3.95 | Epsilon: 0.971 | Failed episodes: 0\n",
      "Episode 600/4000 | Avg Reward: 16.67 | Avg nb gambits played 3.70 | Epsilon: 0.965 | Failed episodes: 0\n",
      "Episode 700/4000 | Avg Reward: 14.40 | Avg nb gambits played 3.72 | Epsilon: 0.959 | Failed episodes: 0\n",
      "Episode 800/4000 | Avg Reward: 14.01 | Avg nb gambits played 3.86 | Epsilon: 0.953 | Failed episodes: 0\n",
      "Episode 900/4000 | Avg Reward: 14.58 | Avg nb gambits played 3.95 | Epsilon: 0.948 | Failed episodes: 0\n",
      "Episode 1000/4000 | Avg Reward: 14.43 | Avg nb gambits played 3.88 | Epsilon: 0.942 | Failed episodes: 0\n",
      "Episode 1100/4000 | Avg Reward: 16.35 | Avg nb gambits played 3.75 | Epsilon: 0.936 | Failed episodes: 0\n",
      "Episode 1200/4000 | Avg Reward: 14.03 | Avg nb gambits played 3.64 | Epsilon: 0.931 | Failed episodes: 0\n",
      "Episode 1300/4000 | Avg Reward: 15.15 | Avg nb gambits played 3.79 | Epsilon: 0.925 | Failed episodes: 0\n",
      "Episode 1400/4000 | Avg Reward: 16.15 | Avg nb gambits played 3.70 | Epsilon: 0.920 | Failed episodes: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m agent \u001b[38;5;241m=\u001b[39m DQNAgent(env,\n\u001b[1;32m      2\u001b[0m                  hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m      3\u001b[0m                  buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m,\n\u001b[1;32m      4\u001b[0m                  epsilon_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.99999\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/arnaud-odet/2_projets/reinforcement_learning/rl_lib/swiss_round/agent.py:179\u001b[0m, in \u001b[0;36mDQNAgent.train\u001b[0;34m(self, n_episodes)\u001b[0m\n\u001b[1;32m    177\u001b[0m gambit_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(action \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     next_state, reward, done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# If pairing fails, abandon this episode and try again\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m#print(f\"Tournament failed: {str(e)}\")\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/code/arnaud-odet/2_projets/reinforcement_learning/rl_lib/swiss_round/environment.py:391\u001b[0m, in \u001b[0;36mSwissRoundEnv.step\u001b[0;34m(self, action, verbose)\u001b[0m\n\u001b[1;32m    388\u001b[0m action_map \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m0\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdraw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlose\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Pair teams and play matches\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pair_teams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;66;03m# Play all matches for this round\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team1, team2 \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;66;03m# Update played_against sets\u001b[39;00m\n",
      "File \u001b[0;32m~/code/arnaud-odet/2_projets/reinforcement_learning/rl_lib/swiss_round/environment.py:374\u001b[0m, in \u001b[0;36mSwissRoundEnv._pair_teams\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimple pairing failed, using networkx matching...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pair_teams_networkx\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pairs\n",
      "File \u001b[0;32m~/code/arnaud-odet/2_projets/reinforcement_learning/rl_lib/swiss_round/environment.py:320\u001b[0m, in \u001b[0;36mSwissRoundEnv._pair_teams_networkx\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    317\u001b[0m         G\u001b[38;5;241m.\u001b[39madd_edge(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam1\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mR\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam2\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, weight\u001b[38;5;241m=\u001b[39mweight)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     matching \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_weight_matching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxcardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;66;03m# Convert matching to pairs of teams\u001b[39;00m\n\u001b[1;32m    323\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m<class 'networkx.utils.decorators.argmap'> compilation 6:5\u001b[0m, in \u001b[0;36margmap_max_weight_matching_1\u001b[0;34m(G, maxcardinality, weight, backend, **backend_kwargs)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/rl_env/lib/python3.10/site-packages/networkx/utils/backends.py:967\u001b[0m, in \u001b[0;36m_dispatchable.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetworkx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m backend is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 967\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# This is purely for aesthetics and to make it easier to search for this\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# variable since \"backend\" is used in many comments and log/error messages.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/rl_env/lib/python3.10/site-packages/networkx/algorithms/matching.py:1022\u001b[0m, in \u001b[0;36mmax_weight_matching\u001b[0;34m(G, maxcardinality, weight)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         labeledge[w] \u001b[38;5;241m=\u001b[39m (v, w)\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m label\u001b[38;5;241m.\u001b[39mget(bw) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;66;03m# keep track of the least-slack non-allowable edge to\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;66;03m# a different S-blossom.\u001b[39;00m\n\u001b[0;32m-> 1022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mbestedge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m kslack \u001b[38;5;241m<\u001b[39m slack(\u001b[38;5;241m*\u001b[39mbestedge[bv]):\n\u001b[1;32m   1023\u001b[0m         bestedge[bv] \u001b[38;5;241m=\u001b[39m (v, w)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m label\u001b[38;5;241m.\u001b[39mget(w) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;66;03m# w is a free vertex (or an unreached vertex inside\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;66;03m# a T-blossom) but we can not reach it yet;\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;66;03m# keep track of the least-slack edge that reaches w.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(env,\n",
    "                 hidden_size=256,\n",
    "                 buffer_size=100000,\n",
    "                 epsilon_decay=0.9995)\n",
    "agent.train(n_episodes=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbosed simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate tournament\n",
    "final_standings = env.simulate_tournament(verbose= True)\n",
    "\n",
    "print(\"\\nFinal standings (team_id, points, opponent_average):\")\n",
    "for rank, (team_id, points, opp_avg,strength) in enumerate(final_standings, 1):\n",
    "\n",
    "    print(f\"Rank {rank}: Team {team_id} - Strength {strength:.2f} - Points: {points} - Opponent Avg: {opp_avg:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
