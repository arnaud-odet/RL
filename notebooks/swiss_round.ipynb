{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from rl_lib.swiss_round.environment import SwissRoundEnv\n",
    "from rl_lib.swiss_round.agent import DQNAgent\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_teams = 18\n",
    "n_rounds = 6\n",
    "team_strengths = [1 * 0.5 ** i for i in range(n_teams)]\n",
    "threshold_ranks = [4,12]\n",
    "bonus_points = [20,20]\n",
    "agent_id = threshold_ranks[-1] #Agent_id just below last threshold\n",
    "n_baselines_simu = 2000\n",
    "\n",
    "env = SwissRoundEnv(\n",
    "    n_teams=n_teams,\n",
    "    n_rounds=n_rounds,\n",
    "    team_strengths=team_strengths,\n",
    "    threshold_ranks=threshold_ranks,\n",
    "    bonus_points=bonus_points,\n",
    "    agent_id=agent_id,\n",
    "    max_draw_probability=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baselines Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating tournaments: 100%|██████████| 1000/1000 [00:03<00:00, 257.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 7 simulations failed out of 1000 (0.7%)\n",
      "Baseline WinAll average reward = 43.2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Team           0.000000\n",
       "Strength       1.000000\n",
       "Avg_Points    11.950655\n",
       "Avg_Rank       4.561934\n",
       "Top-4 %        0.622356\n",
       "Top-12 %       0.939577\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_wa = env.simulate_n_tournaments(n_baselines_simu,\n",
    "                                           n_cores = 32, \n",
    "                                           policy = 'win_all',\n",
    "                                           display_results=False)\n",
    "baseline_reward_wa = simulation_wa.loc[agent_id,'Avg_Points'] + sum([b * simulation_wa.loc[agent_id,f\"Top-{t} %\"] for b,t in zip(\n",
    "    bonus_points, threshold_ranks\n",
    ")])\n",
    "print(f\"Baseline WinAll average reward = {baseline_reward_wa:.1f}\")\n",
    "simulation_wa.loc[agent_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Simulating tournaments: 100%|██████████| 1000/1000 [00:04<00:00, 238.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 4 simulations failed out of 1000 (0.4%)\n",
      "Baseline LoseFirst average reward = 35.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Team           0.000000\n",
       "Strength       1.000000\n",
       "Avg_Points    10.111446\n",
       "Avg_Rank       6.927711\n",
       "Top-4 %        0.412651\n",
       "Top-12 %       0.831325\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulation_lf = env.simulate_n_tournaments(n_baselines_simu,n_cores = 32, policy = 'lose_first',display_results=False)\n",
    "baseline_reward_lf = simulation_lf.loc[agent_id,'Avg_Points'] + sum([b * simulation_lf.loc[agent_id,f\"Top-{t} %\"] for b,t in zip(\n",
    "    bonus_points, threshold_ranks\n",
    ")])\n",
    "print(f\"Baseline LoseFirst average reward = {baseline_reward_lf:.1f}\")\n",
    "simulation_lf.loc[agent_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselines average reward : WinAll = 43.2, LoseFirst = 35.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baselines average reward : WinAll = {baseline_reward_wa:.1f}, LoseFirst = {baseline_reward_lf:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100/6000 | Avg Reward: 14.14 | Avg nb gambits played 3.94 | Epsilon: 0.765 | Failed episodes: 0\n",
      "Episode 200/6000 | Avg Reward: 15.79 | Avg nb gambits played 3.48 | Epsilon: 0.567 | Failed episodes: 0\n",
      "Episode 300/6000 | Avg Reward: 22.28 | Avg nb gambits played 2.91 | Epsilon: 0.419 | Failed episodes: 0\n",
      "Episode 400/6000 | Avg Reward: 28.09 | Avg nb gambits played 2.31 | Epsilon: 0.309 | Failed episodes: 0\n",
      "Episode 500/6000 | Avg Reward: 28.66 | Avg nb gambits played 1.55 | Epsilon: 0.229 | Failed episodes: 0\n",
      "Episode 600/6000 | Avg Reward: 37.35 | Avg nb gambits played 1.26 | Epsilon: 0.168 | Failed episodes: 0\n",
      "Episode 700/6000 | Avg Reward: 35.50 | Avg nb gambits played 0.85 | Epsilon: 0.125 | Failed episodes: 0\n",
      "Episode 800/6000 | Avg Reward: 35.99 | Avg nb gambits played 0.89 | Epsilon: 0.092 | Failed episodes: 0\n",
      "Episode 900/6000 | Avg Reward: 34.93 | Avg nb gambits played 0.80 | Epsilon: 0.068 | Failed episodes: 0\n",
      "Episode 1000/6000 | Avg Reward: 41.60 | Avg nb gambits played 0.74 | Epsilon: 0.050 | Failed episodes: 0\n",
      "Episode 1100/6000 | Avg Reward: 40.87 | Avg nb gambits played 0.64 | Epsilon: 0.037 | Failed episodes: 0\n",
      "Episode 1200/6000 | Avg Reward: 38.07 | Avg nb gambits played 0.77 | Epsilon: 0.028 | Failed episodes: 0\n",
      "Episode 1300/6000 | Avg Reward: 41.19 | Avg nb gambits played 0.52 | Epsilon: 0.020 | Failed episodes: 0\n",
      "Episode 1400/6000 | Avg Reward: 39.18 | Avg nb gambits played 0.65 | Epsilon: 0.015 | Failed episodes: 0\n",
      "Episode 1500/6000 | Avg Reward: 42.58 | Avg nb gambits played 0.64 | Epsilon: 0.011 | Failed episodes: 0\n",
      "Episode 1600/6000 | Avg Reward: 42.62 | Avg nb gambits played 0.51 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 1700/6000 | Avg Reward: 43.03 | Avg nb gambits played 0.53 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 1800/6000 | Avg Reward: 42.29 | Avg nb gambits played 0.48 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 1900/6000 | Avg Reward: 42.50 | Avg nb gambits played 0.28 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2000/6000 | Avg Reward: 41.63 | Avg nb gambits played 0.39 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2100/6000 | Avg Reward: 41.80 | Avg nb gambits played 0.30 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2200/6000 | Avg Reward: 42.97 | Avg nb gambits played 0.34 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2300/6000 | Avg Reward: 40.52 | Avg nb gambits played 0.38 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2400/6000 | Avg Reward: 40.53 | Avg nb gambits played 0.40 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2500/6000 | Avg Reward: 42.18 | Avg nb gambits played 0.31 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2600/6000 | Avg Reward: 43.52 | Avg nb gambits played 0.31 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2700/6000 | Avg Reward: 44.37 | Avg nb gambits played 0.43 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2800/6000 | Avg Reward: 42.05 | Avg nb gambits played 0.40 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 2900/6000 | Avg Reward: 40.78 | Avg nb gambits played 0.52 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3000/6000 | Avg Reward: 41.93 | Avg nb gambits played 0.38 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3100/6000 | Avg Reward: 42.78 | Avg nb gambits played 0.40 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3200/6000 | Avg Reward: 40.49 | Avg nb gambits played 0.31 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3300/6000 | Avg Reward: 43.06 | Avg nb gambits played 0.28 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3400/6000 | Avg Reward: 44.17 | Avg nb gambits played 0.09 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3500/6000 | Avg Reward: 43.31 | Avg nb gambits played 0.11 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3600/6000 | Avg Reward: 42.72 | Avg nb gambits played 0.24 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3700/6000 | Avg Reward: 40.59 | Avg nb gambits played 0.22 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3800/6000 | Avg Reward: 43.66 | Avg nb gambits played 0.21 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 3900/6000 | Avg Reward: 44.09 | Avg nb gambits played 0.13 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4000/6000 | Avg Reward: 43.10 | Avg nb gambits played 0.13 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4100/6000 | Avg Reward: 42.51 | Avg nb gambits played 0.14 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4200/6000 | Avg Reward: 45.19 | Avg nb gambits played 0.11 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4300/6000 | Avg Reward: 44.46 | Avg nb gambits played 0.12 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4400/6000 | Avg Reward: 41.69 | Avg nb gambits played 0.20 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4500/6000 | Avg Reward: 44.90 | Avg nb gambits played 0.16 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4600/6000 | Avg Reward: 43.94 | Avg nb gambits played 0.15 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4700/6000 | Avg Reward: 44.79 | Avg nb gambits played 0.17 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4800/6000 | Avg Reward: 43.47 | Avg nb gambits played 0.11 | Epsilon: 0.010 | Failed episodes: 0\n",
      "Episode 4900/6000 | Avg Reward: 40.83 | Avg nb gambits played 0.14 | Epsilon: 0.010 | Failed episodes: 0\n"
     ]
    }
   ],
   "source": [
    "agent = DQNAgent(env,\n",
    "                 hidden_dims=[256,128,64],\n",
    "                 dropout= 0.1,\n",
    "                 buffer_size=10000,\n",
    "                 epsilon_decay=0.9995)\n",
    "agent.train(n_episodes=6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbosed simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate tournament\n",
    "final_standings = env.simulate_tournament(verbose= True)\n",
    "\n",
    "print(\"\\nFinal standings (team_id, points, opponent_average):\")\n",
    "for rank, (team_id, points, opp_avg,strength) in enumerate(final_standings, 1):\n",
    "\n",
    "    print(f\"Rank {rank}: Team {team_id} - Strength {strength:.2f} - Points: {points} - Opponent Avg: {opp_avg:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
